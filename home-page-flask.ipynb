{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ebc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, url_for\n",
    "import sys, ast, os, json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import itertools\n",
    "import collections\n",
    "from nltk import bigrams\n",
    "import networkx as nx\n",
    "import re\n",
    "import nltk\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441294ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app.config['IMAGES_PATH'] = os.path.join('static', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    #Step 1 - drop links\n",
    "    regex = re.compile(r'https?://t.co/[a-zA-Z0-9]{10}')\n",
    "    remove_links = re.split(regex,tweet)\n",
    "    remove_links = ' '.join(remove_links)\n",
    "    \n",
    "    #Step 2 - Remove any non-ascii characters\n",
    "    remove_non_ascii =  re.sub(r'[^\\x00-\\x7F]+',' ', remove_links).lower()\n",
    "\n",
    "    #Step 3 - check for apostrophes\n",
    "    remove_apostroph = remove_non_ascii.replace(\"'s\",\"\")\n",
    "    remove_apostroph = remove_apostroph.replace(\"'\",\"\")\n",
    "    remove_apostroph = remove_apostroph.split(' ')\n",
    "    \n",
    "    #Step 4 - Remove dashes\n",
    "    remove_dashes = ' '.join(remove_apostroph).split('-')\n",
    "    remove_dashes = ' '.join(remove_dashes)\n",
    "\n",
    "    #Step 5 - Keep letters and digits only\n",
    "    keep_letters =  re.sub(r'[^a-zA-Z0-9]',' ', remove_dashes)\n",
    "\n",
    "    keep_letters = keep_letters.split(' ')\n",
    "\n",
    "    keep_letters = ' '.join(keep_letters)\n",
    "\n",
    "    #Step 6 - Tokenize \n",
    "    tokenize = nltk.word_tokenize(keep_letters)\n",
    "\n",
    "    #Step 7 - Lemmatize    \n",
    "    lemmatizer= nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    lemmatize_text = map(lambda x: lemmatizer.lemmatize(x), tokenize)\n",
    "\n",
    "    #Step 8 - Remove stop words\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    remove_stop = list(filter(lambda x: x not in stopwords, lemmatize_text))\n",
    "\n",
    "    #Step 9 - Remove any empty strings from list\n",
    "    processed_list = list(filter(lambda a: a != \"\", remove_stop))\n",
    "\n",
    "    processed_string = \" \".join(processed_list)\n",
    "\n",
    "    return processed_string\n",
    "\n",
    "def sent_to_list(sentence):\n",
    "    return sentence.split(\" \")\n",
    "\n",
    "def sentiment_analyze(polarity):\n",
    "    if (polarity < 0.1 and polarity > -0.1): return 'neutral'\n",
    "    elif polarity >= 0.1: return 'positive'\n",
    "    else: return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_tweets.csv')\n",
    "df['Year'] = df['Date'].apply(lambda r: r.split('/')[2])\n",
    "df = df[df['Year'] == '2021']\n",
    "df.drop(columns=['Year'], inplace=True)\n",
    "df['Date'] = df['Date'].apply(lambda r: r.split('/')[0])\n",
    "df['Tweet'] = df['Tweet'].apply(lambda tweet: clean_tweet(tweet))\n",
    "df['Words_list'] = df['Tweet'].apply(lambda tweet: sent_to_list(tweet))\n",
    "\n",
    "sentiment_objs = [TextBlob(tweet) for tweet in df['Tweet']]\n",
    "all_senti =[tweet.sentiment.polarity for tweet in sentiment_objs]\n",
    "sentiment_vals = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objs]\n",
    "sentiment_df = pd.DataFrame(sentiment_vals, columns=[\"polarity\", \"tweet\"])\n",
    "\n",
    "neg = sentiment_df['polarity'].astype('float')\n",
    "neg = neg[neg <= -0.1]\n",
    "\n",
    "pos = sentiment_df['polarity'].astype('float')\n",
    "pos = pos[pos >= 0.1]\n",
    "\n",
    "neut = sentiment_df['polarity'].astype('float')\n",
    "neut = neut[neut > -0.1]\n",
    "neut = neut[neut < 0.1]\n",
    "df['Sentiment'] = sentiment_df['polarity']\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: sentiment_analyze(x))\n",
    "\n",
    "df1 = df\n",
    "polarity_by_month = df1[['Date','Tweet','Sentiment']].groupby(['Date','Sentiment'])['Tweet'].count().reset_index().rename(columns={'Tweet':'Tweet_Count'})\n",
    "\n",
    "keywords_by_date = df[['Keyword', 'Date']]\n",
    "keywords_by_date = keywords_by_date[['Keyword', 'Date']].groupby(['Date', 'Keyword'])['Keyword'].count()\n",
    "\n",
    "count = 0\n",
    "month = 0\n",
    "final_vals = []\n",
    "for i in range(0,len(keywords_by_date)):\n",
    "  keyword = \"Covid\" if count%2==0 else \"Corona\"\n",
    "  month = month + 1 if count%2==0 else month\n",
    "  count = count + 1\n",
    "  counts = keywords_by_date[i]\n",
    "  current = [month, keyword, counts]\n",
    "  final_vals.append(current)\n",
    "\n",
    "df2 = pd.DataFrame(final_vals, columns=['Month', 'Keyword', 'Keyword_Count'])\n",
    "w2v_model = Word2Vec()\n",
    "w2v_model.build_vocab(df['Words_list'].tolist())\n",
    "w2v_model.train(df['Words_list'].tolist(), total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "bigram_terms = [list(bigrams(tweet)) for tweet in df['Words_list'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f3a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.figure_factory as ff\n",
    "\n",
    "# sentiment_objs = [TextBlob(tweet) for tweet in df['Tweet']]\n",
    "# all_senti =[tweet.sentiment.polarity for tweet in sentiment_objs]\n",
    "# pos_count = 0\n",
    "# neg_count = 0\n",
    "# neu_count = 0\n",
    "\n",
    "# sentiment_vals = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objs] \n",
    "\n",
    "# sentiment_df = pd.DataFrame(sentiment_vals, columns=[\"polarity\", \"tweet\"])\n",
    "# x = sentiment_df['polarity'].values\n",
    "# fig = sns.displot(x, color='red', kde=True)\n",
    "# mean = sentiment_df['polarity'].mean()\n",
    "# plt.axvline(mean, 0, 1, color = 'blue')\n",
    "\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xlabel('Polarity')\n",
    "\n",
    "# plt.axis([-1, 1, 0, 400])\n",
    "# plt.savefig('Frequency-Polarity.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tsne_scatter(model, word, list_names):\n",
    "#     arrays = np.empty((0,100), dtype='f')\n",
    "#     word_labels = [word]\n",
    "#     color_ls = ['brown']\n",
    "    \n",
    "    \n",
    "#     arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "#     close_words = model.wv.most_similar([word])\n",
    "    \n",
    "#     for word_score in close_words:\n",
    "#         word_vec = model.wv.__getitem__([word_score[0]])\n",
    "#         word_labels.append(word_score[0])\n",
    "#         color_ls.append('blue')\n",
    "#         arrays = np.append(arrays, word_vec, axis=0)\n",
    "        \n",
    "#     for word in list_names:\n",
    "#         word_vec = model.wv.__getitem__([word])\n",
    "#         word_labels.append(word)\n",
    "#         color_ls.append('magenta')\n",
    "#         arrays = np.append(arrays, word_vec, axis=0)\n",
    "    \n",
    "#     reduc = PCA().fit_transform(arrays)\n",
    "    \n",
    "#     np.set_printoptions(suppress=True)\n",
    "#     Y = TSNE(n_components=2, random_state=0, perplexity=10).fit_transform(reduc)\n",
    "    \n",
    "#     df3 = pd.DataFrame({'x':[x for x in Y[:, 0]],\n",
    "#                        'y':[y for y in Y[:,1]],\n",
    "#                        'Words': word_labels,\n",
    "#                        'color': color_ls})\n",
    "#     fig, _ = plt.subplots()\n",
    "#     fig.set_size_inches(10,10)\n",
    "    \n",
    "#     p = sns.regplot(data=df3,\n",
    "#                    x='x',\n",
    "#                    y='y',\n",
    "#                    fit_reg=False,\n",
    "#                    marker='x',\n",
    "#                    scatter_kws={'s':40,\n",
    "#                                'facecolors':df3['color']}\n",
    "#                    )\n",
    "    \n",
    "#     for line in range(0, df3.shape[0]):\n",
    "#         p.text(df3['x'][line],\n",
    "#               df3['y'][line],\n",
    "#               ' ' + df3['Words'][line].title(),\n",
    "#               horizontalalignment='left',\n",
    "#               verticalalignment='bottom', size = 'medium',\n",
    "#               color = df3['color'][line],\n",
    "#               weight='normal',\n",
    "#               ).set_size(15)\n",
    "    \n",
    "#     plt.xlim(Y[:, 0].min() - 50, Y[:, 0].max()+50)\n",
    "#     plt.ylim(Y[:, 1].min() - 50, Y[:, 1].max()+50)\n",
    "    \n",
    "#     plt.title(\"t-SNE visulization\")\n",
    "#     plt.savefig('t-sne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f55f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_bigram(bigram_terms):\n",
    "#     bigrams = list(itertools.chain(*bigram_terms))\n",
    "#     bigrams_count = collections.Counter(bigrams)\n",
    "\n",
    "#     bg_df = pd.DataFrame(bigrams_count.most_common(19), columns=['Bigrams', 'Count'])\n",
    "#     bg_df = bg_df.drop(labels=[1,2,3,10], axis=0)\n",
    "\n",
    "#     d = bg_df.set_index('Bigrams').T.to_dict('dict_records')\n",
    "\n",
    "#     G = nx.Graph()\n",
    "\n",
    "#     for k in d:\n",
    "#         G.add_edge(k[0],k[1],weight=(d[k]['Count']*5))\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize = (12,10))\n",
    "#     pos = nx.spring_layout(G, k=4)\n",
    "\n",
    "#     nx.draw_networkx(G, pos,\n",
    "#                     font_size=10,\n",
    "#                     width=2,\n",
    "#                     edge_color='brown',\n",
    "#                     node_color='#008080',\n",
    "#                     with_labels=False,\n",
    "#                     ax=ax)\n",
    "\n",
    "#     for key, value in pos.items():\n",
    "#         x,y = value[0]+.135, value[1]+.045\n",
    "#         ax.text(x,y,\n",
    "#               s=key,\n",
    "#               bbox=dict(facecolor='black', alpha=0.25),\n",
    "#               horizontalalignment='center', fontsize=10)\n",
    "\n",
    "#     plt.title('Most occuring bigrams in the Tweets')\n",
    "#     plt.savefig('bigrams.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_scatter(w2v_model, 'covid19', ['corona', 'infection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6716b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_bigram(bigram_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fec105",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_polarity = px.bar(df,\n",
    "                          x=['Positive', 'Neutral', 'Negative'],\n",
    "                          y=[len(pos), len(neut), len(neg)],\n",
    "                          labels = {'x':'Distribution of Sentiments', 'y':'Number of Tweets'}\n",
    "                        )\n",
    "tw_polarity = px.line(polarity_by_month, x='Date', y='Tweet_Count', color='Sentiment', color_discrete_sequence=['brown','orange','green'])\n",
    "f = px.line(df2, x='Month', y='Keyword_Count', color='Keyword', color_discrete_sequence=['brown', 'magenta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def home_page():\n",
    "#     filename1 = os.path.join(app.config['IMAGES_PATH'], 'Frequency-Polarity.png')\n",
    "#     filename2 = os.path.join(app.config['IMAGES_PATH'], 't-sne.png')\n",
    "#     filename3 = os.path.join(app.config['IMAGES_PATH'], 'bigrams.png')\n",
    "    graph1JSON = json.dumps(tweet_polarity, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "    graph2JSON = json.dumps(tw_polarity, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "    graph3JSON = json.dumps(f, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "    return render_template('blockcontent.html',\n",
    "                           graph1JSON = graph1JSON, \n",
    "                           graph2JSON = graph2JSON, \n",
    "                           graph3JSON = graph3JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1609a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
